{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import ConvexHullDataset as mixup\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "\n",
    "mixup = reload(mixup)\n",
    "\n",
    "outfname = \"cvxCIFAR10dataset.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Datatype of feature vectors: <class 'PIL.Image.Image'>\n",
      "On row batch 1 of 17\n",
      "On row batch 2 of 17\n",
      "On row batch 3 of 17\n",
      "On row batch 4 of 17\n",
      "On row batch 5 of 17\n",
      "On row batch 6 of 17\n",
      "On row batch 7 of 17\n",
      "On row batch 8 of 17\n",
      "On row batch 9 of 17\n",
      "On row batch 10 of 17\n",
      "On row batch 11 of 17\n",
      "On row batch 12 of 17\n",
      "On row batch 13 of 17\n",
      "On row batch 14 of 17\n",
      "On row batch 15 of 17\n",
      "On row batch 16 of 17\n",
      "On row batch 17 of 17\n",
      "Computing sample 1 of 100000\n",
      "Computing sample 1001 of 100000\n",
      "Computing sample 2001 of 100000\n",
      "Computing sample 3001 of 100000\n",
      "Computing sample 4001 of 100000\n",
      "Computing sample 5001 of 100000\n",
      "Computing sample 6001 of 100000\n",
      "Computing sample 7001 of 100000\n",
      "Computing sample 8001 of 100000\n",
      "Computing sample 9001 of 100000\n",
      "Computing sample 10001 of 100000\n",
      "Computing sample 11001 of 100000\n",
      "Computing sample 12001 of 100000\n",
      "Computing sample 13001 of 100000\n",
      "Computing sample 14001 of 100000\n",
      "Computing sample 15001 of 100000\n",
      "Computing sample 16001 of 100000\n",
      "Computing sample 17001 of 100000\n",
      "Computing sample 18001 of 100000\n",
      "Computing sample 19001 of 100000\n",
      "Computing sample 20001 of 100000\n",
      "Computing sample 21001 of 100000\n",
      "Computing sample 22001 of 100000\n",
      "Computing sample 23001 of 100000\n",
      "Computing sample 24001 of 100000\n",
      "Computing sample 25001 of 100000\n",
      "Computing sample 26001 of 100000\n",
      "Computing sample 27001 of 100000\n",
      "Computing sample 28001 of 100000\n",
      "Computing sample 29001 of 100000\n",
      "Computing sample 30001 of 100000\n",
      "Computing sample 31001 of 100000\n",
      "Computing sample 32001 of 100000\n",
      "Computing sample 33001 of 100000\n",
      "Computing sample 34001 of 100000\n",
      "Computing sample 35001 of 100000\n",
      "Computing sample 36001 of 100000\n",
      "Computing sample 37001 of 100000\n",
      "Computing sample 38001 of 100000\n",
      "Computing sample 39001 of 100000\n",
      "Computing sample 40001 of 100000\n",
      "Computing sample 41001 of 100000\n",
      "Computing sample 42001 of 100000\n",
      "Computing sample 43001 of 100000\n",
      "Computing sample 44001 of 100000\n",
      "Computing sample 45001 of 100000\n",
      "Computing sample 46001 of 100000\n",
      "Computing sample 47001 of 100000\n",
      "Computing sample 48001 of 100000\n",
      "Computing sample 49001 of 100000\n",
      "Computing sample 50001 of 100000\n",
      "Computing sample 51001 of 100000\n",
      "Computing sample 52001 of 100000\n",
      "Computing sample 53001 of 100000\n",
      "Computing sample 54001 of 100000\n",
      "Computing sample 55001 of 100000\n",
      "Computing sample 56001 of 100000\n",
      "Computing sample 57001 of 100000\n",
      "Computing sample 58001 of 100000\n",
      "Computing sample 59001 of 100000\n",
      "Computing sample 60001 of 100000\n",
      "Computing sample 61001 of 100000\n",
      "Computing sample 62001 of 100000\n",
      "Computing sample 63001 of 100000\n",
      "Computing sample 64001 of 100000\n",
      "Computing sample 65001 of 100000\n",
      "Computing sample 66001 of 100000\n",
      "Computing sample 67001 of 100000\n",
      "Computing sample 68001 of 100000\n",
      "Computing sample 69001 of 100000\n",
      "Computing sample 70001 of 100000\n",
      "Computing sample 71001 of 100000\n",
      "Computing sample 72001 of 100000\n",
      "Computing sample 73001 of 100000\n",
      "Computing sample 74001 of 100000\n",
      "Computing sample 75001 of 100000\n",
      "Computing sample 76001 of 100000\n",
      "Computing sample 77001 of 100000\n",
      "Computing sample 78001 of 100000\n",
      "Computing sample 79001 of 100000\n",
      "Computing sample 80001 of 100000\n",
      "Computing sample 81001 of 100000\n",
      "Computing sample 82001 of 100000\n",
      "Computing sample 83001 of 100000\n",
      "Computing sample 84001 of 100000\n",
      "Computing sample 85001 of 100000\n",
      "Computing sample 86001 of 100000\n",
      "Computing sample 87001 of 100000\n",
      "Computing sample 88001 of 100000\n",
      "Computing sample 89001 of 100000\n",
      "Computing sample 90001 of 100000\n",
      "Computing sample 91001 of 100000\n",
      "Computing sample 92001 of 100000\n",
      "Computing sample 93001 of 100000\n",
      "Computing sample 94001 of 100000\n",
      "Computing sample 95001 of 100000\n",
      "Computing sample 96001 of 100000\n",
      "Computing sample 97001 of 100000\n",
      "Computing sample 98001 of 100000\n",
      "Computing sample 99001 of 100000\n"
     ]
    }
   ],
   "source": [
    "# Using torchvision normalize -> [-1, 1]\n",
    "normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                 std=[0.5, 0.5, 0.5])\n",
    "\n",
    "CIFAR_traindataset= datasets.CIFAR10(root='./cifar10', train=True, download=True)\n",
    "\n",
    "maxn = 10\n",
    "cvxCIFAR10traindataset = mixup.ConvexHullDataset(\n",
    "    CIFAR_traindataset, \n",
    "    batchsize=3000, \n",
    "    maxneighbors=maxn,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]), \n",
    "    store=True)\n",
    "\n",
    "cvxCIFAR10traindataset.save(outfname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outfname, 'rb') as fin:\n",
    "    dset = torch.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConvexHullDataset.ConvexHullDataset at 0x7f3507fe48d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, dtype=torch.float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset[0][2].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
